{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1>分類での評価方法</h1>\n",
    "\n",
    "分類において使う主な評価指標は以下の通りです。\n",
    "\n",
    "・混同行列（Confusion matrix）\n",
    "\n",
    "・精度（Accuracy）\n",
    "\n",
    "・適合率（Precision）\n",
    "\n",
    "・再現率（Recall）\n",
    "\n",
    "・F値（F-measure）\n",
    "\n",
    "一つずつ見ていきましょう。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>混同行列とは</h2>\n",
    "混同行列は二値分類（正事例と負事例の予測）をするときに使用されます。\n",
    "\n",
    "真の値と予測した値の組み合わせには、それぞれ名称があり以下のように呼ばれます。\n",
    "\n",
    "True Positive(TP) ・・・真の値が正事例のものに対して，正事例と予測したもの\n",
    "\n",
    "False Positive(FP) ・・・真の値が負事例のものに対して，正事例と予測したもの\n",
    "\n",
    "False Negative(FN) ・・・真の値が正事例のものに対して，負事例と予測したもの\n",
    "\n",
    "True Negative(TN) ・・・真の値が負事例のものに対して，負事例と予測したもの\n",
    "\n",
    "このTP,FP,FN,TNの値を可視化したものが混合行列です。\n",
    "\n",
    "プログラムを入力して、混合行列をみてみましょう。\n",
    "まず、データを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test=[0,0,0,0,0,1,1,1,1,1]\n",
    "y_pred=[0,1,0,0,0,0,0,1,1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_testは真の値、y_predは機械学習によって予測した値です。\n",
    "\n",
    "次に、scikit-learnのconfusion matrixによって混同行列を可視化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 1]\n",
      " [2 3]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>精度</h2>\n",
    "<p>精度とは、予測結果全体がどれくらい真の値と一致しているかを表す指標です。</p>\n",
    "<p>Accuracy = (TP + TN) / (TP + FP + FN + TN)</p>\n",
    "<p>精度は、accyracy_scoreで求めることができる</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acucracy: 0.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Acucracy:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実行すると、\n",
    "\n",
    "Accuracy: 0.7\n",
    "\n",
    "と出力されます。\n",
    "\n",
    "<h3>注意すべき点は、精度がよければよいモデルというわけではないということです.</h3>\n",
    "\n",
    "例えば、\n",
    "\n",
    "真の値が[1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
    "\n",
    "と負事例が1つのものだとします。\n",
    "\n",
    "機械学習をした結果、\n",
    "\n",
    "予測の値が[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "となったとき精度は90%と計算され一見よいモデルと思えます。\n",
    "\n",
    "しかし、1個の負事例を予測できていないためこのモデルは意味がない可能性があります。\n",
    "\n",
    "このように正事例と負事例が不均衡なデータに対し精度を使って評価するのは難しいため、精度以外にも様々な指標があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>適合率（Precsion）</h2>\n",
    "<p>適合地とは、正事例と予測したもののなかで、真の値が正事例の割合を表す指標。</p>\n",
    "\n",
    "<h4>Precision = TP / TP + FP</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>再現率（Recall）</h2>\n",
    "<p>再現率とは、真の値が正事例のもののなかで正事例と予測した割合を表す指標</p>\n",
    "\n",
    "<h4> Recall = TP / TP + FN</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>F値（F-measure）</h2>\n",
    "<p>適合率と再現率はトレードオフの関係にあるので、二つの指標をまとめた指標としてF値がある</p>\n",
    "\n",
    "<p>F値は、適合率と再現率の調和平均によって計算される</p>\n",
    "\n",
    "<h3>F-measure = 2Precision * Recall / Precision + Recall </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>適合率、再現率、F値はscikit-learnのCunfusion matrixによって計算される</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.80      0.73         5\n",
      "          1       0.75      0.60      0.67         5\n",
      "\n",
      "avg / total       0.71      0.70      0.70        10\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.67      0.73         6\n",
      "          1       0.60      0.75      0.67         4\n",
      "\n",
      "avg / total       0.72      0.70      0.70        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"classification report\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>回帰での評価</h2>\n",
    "<p>評価指標は、分類だけでなく回帰にも適用できる。</p>\n",
    "<p>回帰で使われる評価指標でメジャーなものは以下の二つ<p>\n",
    "<li>二乗平均平方根誤差(RMSE)</li>\n",
    "<li>決定係数(R2)</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>二乗平均平方根誤差</h2>\n",
    "二乗平均平方根誤差(RMSE) とは、\n",
    "実際の値と予測値の差の絶対値の2乗をデータの総数で割り、平均したものです。\n",
    "\n",
    "ちなみにRMSEは\"Root Mean Squared Error\"の略です。\n",
    "\n",
    "この値が小さければ小さいほど、誤差の小さいモデルであると言えます。\n",
    "\n",
    "数式では二乗平均平方根誤差は以下のように表せます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE\n",
    "RMSE = sqrt((1/n)sum(y_test - y_pred)^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '実際の値' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-2bbf6a3e46e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msqrt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mrmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m実際の値\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m予測した値\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name '実際の値' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "rmse = sqrt(mean_squared_error(実際の値, 予測した値)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 決定係数\n",
    "決定係数(R2)とは、推定された回帰式の当てはまりの良さ（度合い）を表します。\n",
    "0から1までの値を取り、1に近いほど、回帰式が実際のデータに当てはまっていることを表しており、説明変数が目的変数を説明していると言えます。\n",
    "逆に0に近ければあまり良くない性能であることを示します。\n",
    "\n",
    "R2=1−∑n−1i=0(yi−^yi)2∑\n",
    "n\n",
    "−\n",
    "1\n",
    "i\n",
    "=\n",
    "0\n",
    "(\n",
    "y\n",
    "i\n",
    "−\n",
    "¯\n",
    "y\n",
    "i\n",
    ")\n",
    "2\n",
    "（ \n",
    "y\n",
    "i\n",
    ":実際の値、 \n",
    "^\n",
    "y\n",
    "i\n",
    ":予測値、\n",
    "¯\n",
    "y\n",
    "i\n",
    ":平均値、 \n",
    "n\n",
    ":データの総数 ）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "model = LinearRegression\n",
    "model.fit(X, y)\n",
    "result = model.score(x, y)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分類と回帰に使える評価方法\n",
    "最後に、分類でも回帰でも使える評価方法の交差検証とグリッドサーチについて説明します。\n",
    "\n",
    "２つの手法の意味は以下の通りです。\n",
    "\n",
    "・交差検証（Cross-validation）：個々のモデルの汎化性能を評価する手法\n",
    "\n",
    "・グリッドサーチ（grid search）：機械学習のハイパーパラメータ探索の方法\n",
    "\n",
    "それでは、一つずつ詳細を見ていきましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ホールドアウト法\n",
    "ホールドアウト法は、モデルを作る学習データと、\n",
    "モデルを評価するテストデータに分割して評価します。\n",
    "\n",
    "データを分けることで、汎化性能（未知のデータに対する性能）を向上させることができます。\n",
    "\n",
    "もし、未知のデータを予測するにあたり全てのデータを学習データにしてしまうと、過学習(学習データにだけ精度の高いモデルでそれ以外の未学習のデータに対して正しく答えを出力できない状態)してしまいます。\n",
    "\n",
    "scikit-learnのtrain_test_split()を使うことでデータを分けることが可能です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 交差検定(クロスバリデーション)\n",
    "機械学習を行うとき、学習を行うための学習データと未知のデータに適用したときの精度を評価するためのテストデータがあります。\n",
    "\n",
    "トレーニングデータでの性能がとても良いのにもかかわらず、テストデータでの性能悪くなってしまうことを過学習と言います。\n",
    "\n",
    "この節では、過学習をしないように学習モデルを評価する交差検証について理解しましょう。\n",
    "\n",
    "ちなみに、交差検証は分類でも回帰でも使える手法です。\n",
    "\n",
    "そのなかで、一番使われるK-分割交差検定について説明します。\n",
    "\n",
    "K-分割交差検定は、データをK個に分割してそのうち1つをテストデータに残りのK-1個を学習データとして精度の評価を行います。\n",
    "\n",
    "これをK個のデータすべてが1回ずつテストデータになるようにK回学習を行なって精度の平均をとる手法です。\n",
    "\n",
    "過学習していないか確認するために、交差検定は必ず行いましょう。\n",
    "\n",
    "交差検定をするための関数は以下のようになります。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from scipy.stats import sem\n",
    "\n",
    "def evaluate_cross_validation(clf, x, y, K):\n",
    "    cv = KFold(len(y), K, shuffle = True, random_state=0)\n",
    "    scores = cross_val_score(clf, x, y, cv = cv )\n",
    "    print(scores)\n",
    "    prinit(\"Mean score :{} (+/-{})\".format( np.mean(scores), sem(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "引数1番目のclfは機械学習モデル（決定木、SVMなど）です。\n",
    "\n",
    "引数最後のKはデータを何分割するか指定する引数です。 \n",
    "\n",
    "train_test_splitのmoduleが0.20から変わり、\n",
    "\n",
    "sckit-learnバージョンが0.18でDeprecationWarningが出ます。\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "でワーニングエラーが出た場合、下記新しいmoduleからimportしてください。\n",
    "\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## グリッドサーチ\n",
    "\n",
    "交差検証はモデルの汎化性能を測定する方法でした。\n",
    "\n",
    "それに対してグリッドサーチは、学習モデルに用いられるハイパーパラメータを調整していき、モデルの汎化性能を向上させる方法を探す代表的な手法です。\n",
    "\n",
    "グリッドサーチでは、指定したハイパーパラメータの全ての組み合わせに対して学習を行い、もっとも良い精度を示したパラメータを採用していきます。\n",
    "\n",
    "ハイパーパラメータとは、SVCでのカーネルのバンド幅gamma、正則化パラメータCなどのことです。\n",
    "\n",
    "このパラメータはモデルの性能に大きく影響を与えます。\n",
    "\n",
    "例えば、ハイパーパラメータであるgammmaとCにそれぞれ0.001, 0.005, 0.1, 1, 5などと当てはめて、\n",
    "モデルの汎化性能を試してみるだけで、5×5=25通りのハイパーパラメータの組み合わせがありますが、それら全ての中で汎化性能の一番良いものを採択します。\n",
    "\n",
    "グリッドサーチはScikit-learnを用いて実装できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\masayoshi\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\masayoshi\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、最適化したいモデルのハイパーパラメータの設定を行いましょう。\n",
    "例えば、 SVMにおいて、Cとgammaをそれぞれ{1,5,10,50},{0.001,0.0001}で最適化したいとすると、このようにリスト内に、keyにCとgammaを持つ辞書を入れれば良いです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = [\n",
    "    {'C':[1, 5, 10, 50],\n",
    "     'gamma':[0.001, 0.0001]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-c48c309f1c99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msvc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.grid_scores_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 評価まとめ\n",
    "<p>以上の評価指標をまとめて出力させる関数を作っておくと非常に便利</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def measure_performance(x, y, clf, show_accuracy=True, show_classification_report=True,show_confussion_matrix = True):\n",
    "    y_pred = clf.predict(x)\n",
    "    if show_accuracy:\n",
    "        print(\"Accuracy:{0:.3f}\".format(metrics.accuracy_score(y, y_pred)), \"\\n\")\n",
    "    \n",
    "    if show_classification_report:\n",
    "        print(\"Classification report\")\n",
    "        print(metrics.classification_report(y, y_pred), \"\\n\")\n",
    "    \n",
    "    if show_confussion_matrix:\n",
    "        print(\"Cunfussion matrix\")\n",
    "        print(metrics.confusion_matrix(y, y_pred), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if show_accuracy:\n",
    "\n",
    "if show_classification_report:\n",
    "\n",
    "if show_confussion_matrix:\n",
    "\n",
    "ですが条件文にしている理由は、その関数がパフォーマンスの非表示をするためのものだからです。\n",
    "\n",
    "関数はデフォルト引数で全てTrueを取っているため、そのまま呼び出すと全ての評価指標について出力しますが、例えばaccuracyだけ欲しい時などがあります。\n",
    "\n",
    "そこでそれ以外をFalseに指定して, その関数を使うということがあります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 今回作成したプログラム"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 1]\n",
      " [2 3]]\n",
      "Accuracy: 0.7\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.80      0.73         5\n",
      "          1       0.75      0.60      0.67         5\n",
      "\n",
      "avg / total       0.71      0.70      0.70        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test = [0,0,0,0,0,1,1,1,1,1]\n",
    "y_pred = [0,1,0,0,0,0,0,1,1,1]\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Classification report\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#評価指標をすべて出力する関数\n",
    "from sklearn import metrics\n",
    "def measure_performanve(x, y, clf, show_accuracy = True, show_classification_report = True, show_confusion_matrix = True):\n",
    "    y_pred = clf.predict(x)\n",
    "    if show_accuracy:\n",
    "        print(\"Accuracy:{0:.3f}\".format(metrics.accuracy_score(y, y_pred)), \"\\n\")\n",
    "        \n",
    "    if show_classificaiton_report:\n",
    "        print(\"Classification report\")\n",
    "        print(metrics.classification_report(y, y_pred), \"/n\")\n",
    "        \n",
    "    if show_confusion_matrix:\n",
    "        print(\"Confussion matrix\")\n",
    "        print(metrics.confussion_matrix(y, t_pred),\"/n\")\n",
    "        \n",
    "#交差検証\n",
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "from scipy.stats import sem\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_cross_validation(clf, x, y, K):\n",
    "    cv = KFold(len(y), K, shuffle=True, random_state = 0)\n",
    "    scores = cross_val_score(clf, x, y, cv = cv)\n",
    "    print(scores)\n",
    "    print(\"Mean score: {} (+/-{})\".format( np.mean(scores), sem(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# まとめ\n",
    "この章では、過学習していないか確かめるために交差検定や分類と回帰における評価指標について学びました。\n",
    "\n",
    "分類の評価指標には、精度、適合率、再現率、F値などがあります。\n",
    "\n",
    "回帰の評価指標には、平均二乗誤差や決定係数などがあります。\n",
    "\n",
    "今後この節で学んだことを活かし、システムに組み込む前に機械学習の結果を評価して頂ければと思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 演習問題\n",
    "\n",
    "１）正解ラベルが\n",
    "y_test = [0,2,0,1,0,1,1,2,0,1,2,0,0]\n",
    "\n",
    "予測したラベルが\n",
    "y_pred = [0,2,0,2,0,1,2,0,0,1,2,0,0]\n",
    "\n",
    "とします。\n",
    "\n",
    "このときの、精度、適合率、再現率、f値、混合行列を出力してください。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.769230769231\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92         6\n",
      "          1       1.00      0.50      0.67         4\n",
      "          2       0.50      0.67      0.57         3\n",
      "\n",
      "avg / total       0.82      0.77      0.76        13\n",
      "\n",
      "[[6 0 0]\n",
      " [0 2 2]\n",
      " [1 0 2]]\n"
     ]
    }
   ],
   "source": [
    "y_test = [0,2,0,1,0,1,1,2,0,1,2,0,0]\n",
    "y_pred = [0,2,0,2,0,1,2,0,0,1,2,0,0]\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#精度\n",
    "print('Accuracy:',accuracy_score(y_test,y_pred))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#適合率、再現率、F値\n",
    "print(\"Classification report\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#混同行列\n",
    "confusion_matrix = confusion_matrix(y_test,y_pred)\n",
    "print(confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
